{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1588316-c7e3-4a8b-899f-220ff535b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:52:09) \n",
      "[Clang 14.0.6 ]\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f5442a-d813-4c2a-b1e0-57d9ff3bbe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(name=accuracy,dtype=float32)\n",
      "Mean(name=mean,dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. metrics 性能指标\n",
    "加权平均值： tf.keras.metrics.Mean\n",
    "预测值和真实值的准确度： tf.keras.metrics.Accuracy\n",
    "\n",
    "1.1 新建一个metrics指标\n",
    "准确度指标 metrics.Accuracy() 一般用于训练集，加权平均值 metrics.Mean()  一般用于测试集\n",
    "\"\"\"\n",
    "from tensorflow.keras import metrics\n",
    "# 新建准确度指标\n",
    "acc_meter = metrics.Accuracy() \n",
    "print(acc_meter)\n",
    "# 新建平均值指标\n",
    "mean_meter = metrics.Mean()  \n",
    "print(mean_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21144070-edf8-47c4-89e7-4c103388a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.2 向metrics添加数据\n",
    "添加数据：update_state()。每一次迭代，都向准确率指标中添加测试数据的真实值和测试数据的预测值，将准确率保存在缓存区，需要时取出来。\n",
    "向平均损失指标中添加每一次训练产生的损失，每添加进来一个值就计算加权平均值，\n",
    "sample_weight指定每一项的权重，将结果保存在缓存区，需要时取出来。\n",
    "\"\"\"\n",
    "# 计算真实值和预测值之间的准确度\n",
    "acc_meter.update_state(y_true, predict) \n",
    "# 计算平均损失\n",
    "mean_meter = mean_meter.update_state(loss, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bfc0b-2c56-4440-80a0-910ee80d782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.3 从metrics中取出数据\n",
    "取出数据：result().numpy()。result()返回tensor类型数据，转换成numpy()类型的数据。\n",
    "\"\"\"\n",
    "# 取出准确率\n",
    "acc_meter.result().numpy() \n",
    "# 取出训练集的损失值的均值\n",
    "mean_meter.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d79dc-8569-4d4f-b811-c3aaf74137b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "清空缓存：reset_states()。每一次循环缓存区都会将之前的数据保存，在开始第二次循环之前，应该把缓存区清空，重新读入数据。\n",
    "\"\"\"\n",
    "# 清空准确率的缓存\n",
    "acc_meter.reset_states()\n",
    "# 清空加权均值的缓存\n",
    "mean_meter.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd1653-8a6e-4484-b2ce-683795178cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. compile 模型配置\n",
    "compile(optimizer, loss, metrics, loss_weights)\n",
    "参数设置：\n",
    "optimizer： 用来配置模型的优化器，可以调用tf.keras.optimizers API配置模型所需要的优化器。\n",
    "loss： 用来配置模型的损失函数，可以通过名称调用tf.losses API中已经定义好的loss函数。\n",
    "metrics： 用来配置模型评价的方法，模型训练和测试过程中的度量指标，如accuracy、mse等\n",
    "loss_weights： float类型，损失加权系数，总损失是所有损失的加权和，它的元素个数和模型的输出数量是1比1的关系。\n",
    "\"\"\"\n",
    "# 选择优化器Adam，loss为交叉熵损失，测试集评价指标accurancy\n",
    "network.compile(optimizer=optimizers.legacy.Adam(learning_rate=0.01) , #学习率0.01\n",
    "    loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b8a1f-cee1-41f8-bf03-bd78a3b37938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. fit 模型训练\n",
    "fit(x, y, batch_size, epochs, validation_split, validation_data, shuffle, validation_freq)\n",
    "参数：\n",
    "x： 训练集的输入数据，可以是array或者tensor类型。\n",
    "y： 训练集的目标数据，可以是array或者tensor类型。\n",
    "batch_size：每一个batch的大小，默认32\n",
    "epochs： 迭代次数\n",
    "validation_split：配置测试集数据占训练数据集的比例，取值范围为0～1。\n",
    "validation_data： 配置测试集数据(输入特征及目标)。如果已经配置validation_split参数，则可以不配置该参数。\n",
    "    如果同时配置validation_split和validation_data参数，那么validation_split参数的配置将会失效。\n",
    "shuffle：配置是否随机打乱训练数据。当配置steps_per_epoch为None时，本参数的配置失效。\n",
    "validation_freq： 每多少次循环做一次测试\n",
    "\"\"\"\n",
    "# ds为包含输入特征及目标的数据集\n",
    "network.fit(ds, eopchs=20, validation_data=ds_val, validation_freq=2)\n",
    "# validation_data给定测试集，validation_freq每多少次大循环做一次测试，测试时自动计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b984b7-e98e-4cb4-a896-0d04e732601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. evaluate 模型评估\n",
    "evaluate(x, y, batch_size, sample_weight, steps)\n",
    "返回模型的损失及准确率等相关指标\n",
    "\n",
    "参数：\n",
    "x： 输入测试集特征数据\n",
    "y：测试集的目标数据\n",
    "batch_size： 整数或None。每个梯度更新的样本数。如果未指定，batch_size将默认为32。如果数据采用数据集，生成器形式，则不要指定batch_size。\n",
    "sample_weight： 测试样本的可选Numpy权重数组，用于加权损失函数。\n",
    "steps： 整数或None。宣布评估阶段结束之前的步骤总数。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470839f-aac6-4ff6-b344-d7ff65ed8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. predict 预测\n",
    "predict(x, batch_size, steps)\n",
    "参数：\n",
    "\n",
    "x： numpy类型，tensor类型。预测所需的特征数据\n",
    "batch_size： 每个梯度更新的样本数。如果未指定，batch_size将默认为32\n",
    "steps： 整数或None，宣布预测回合完成之前的步骤总数（样本批次）。\n",
    "等同于：\n",
    "\"\"\"\n",
    "sample = next(iter(ds_pred)) # 每次从验证数据中取出一组batch\n",
    "x = sample[0] # x 保存第0组验证集特征值\n",
    "pred = network.predict(x)  # 获取每一个分类的预测结果\n",
    "pred = tf.argmax(pred, axis=1) # 获取值最大的所在的下标即预测分类的结果\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813411a-f487-40ba-8a90-784fd4f9ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. sequential\n",
    "Sequential模型适用于简单堆叠网络层，即每一层只有一个输入和一个输出。\n",
    "\"\"\"\n",
    "# ==1== 设置全连接层\n",
    "# [b,784]=>[b,256]=>[b,128]=>[b,64]=>[b,32]=>[b,10]，中间层一般从大到小降维\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'), #第一个连接层，输出256个特征\n",
    "    layers.Dense(128, activation='relu'), #第二个连接层\n",
    "    layers.Dense(64, activation='relu'), #第三个连接层\n",
    "    layers.Dense(32, activation='relu'), #第四个连接层\n",
    "    layers.Dense(10), #最后一层不需要激活函数，输出10个分类\n",
    "    ])\n",
    "# ==2== 设置输入层维度\n",
    "network.build(input_shape=[None, 28*28])\n",
    "# ==3== 查看网络结构\n",
    "network.summary()\n",
    "# ==4== 查看网络的所有权重和偏置\n",
    "network.trainable_variables\n",
    "# ==5== 自动把x从第一层传到最后一层\n",
    "network.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e420d5-8cde-4a2a-9ab6-4d40848f53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "7. 自定义层构建网络\n",
    "通过对 tf.keras.Model 进行子类化并定义自己的前向传播模型。在 __init__ 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播。\n",
    "\"\"\"\n",
    "# 自定义Dense层\n",
    "class MyDense(layers.Layer): #必须继承layers.Layer层，放到sequential容器中\n",
    "    # 初始化方法\n",
    "    def __int__(self, input_dim, output_dim):\n",
    "        super(MyDense, self).__init__() # 调用母类初始化，必须\n",
    "        \n",
    "        # 自己发挥'w''b'指定名字没什么用，创建shape为[input_dim, output_dim的权重\n",
    "        # 使用add_variable创建变量\n",
    "        self.kernel = self.add_variable('w', [input_dim, output_dim])\n",
    "        self.bias = self.add_variable('b', [output_dim])\n",
    "    \n",
    "    # call方法，training来指示现在是训练还是测试\n",
    "    def call(self, inputs, training=None):\n",
    "        out = inputs @ self.kernel + self.bias\n",
    "        return out\n",
    " \n",
    " \n",
    "# 自定义层来创建网络\n",
    "class MyModel(keras.Model):  # 必须继承keras.Model大类，才能使用complie、fit等功能\n",
    "    # \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__() # 调用父类Mymodel\n",
    "        # 使用自定义层创建5层\n",
    "        self.fc1 = MyDense(28*28,256) #input_dim=784，output_dim=256\n",
    "        self.fc2 = MyDense(256,128)\n",
    "        self.fc3 = MyDense(128,64)\n",
    "        self.fc4 = MyDense(64,32)\n",
    "        self.fc5 = MyDense(32,10)\n",
    " \n",
    "    def call(self, inputs, training=None):\n",
    "        # x从输入层到输出层\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)        \n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc5(x) #logits层\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
