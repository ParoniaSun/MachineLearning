{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943a0efd-f314-4fdd-b974-f54bacd74717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.11 (main, Dec 11 2024, 10:25:04) [Clang 14.0.6 ]\n",
      "2.5.1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import torch\n",
    "\n",
    "# 当前安装的 PyTorch 库的版本\n",
    "print(torch.__version__)\n",
    "# 检查 CUDA 是否可用，即你的系统有 NVIDIA 的 GPU\n",
    "print(torch.backends.mps.is_available()) #检查mps是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7cbeb-c17f-45ff-9648-a5a0a39a57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch 数据处理与加载的介绍：\n",
    "\n",
    "自定义 Dataset：通过继承 torch.utils.data.Dataset 来加载自己的数据集。\n",
    "DataLoader：DataLoader 按批次加载数据，支持多线程加载并进行数据打乱。\n",
    "数据预处理与增强：使用 torchvision.transforms 进行常见的图像预处理和增强操作，提高模型的泛化能力。\n",
    "加载标准数据集：torchvision.datasets 提供了许多常见的数据集，简化了数据加载过程。\n",
    "多个数据源：通过组合多个 Dataset 实例来处理来自不同来源的数据。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd58db24-0c46-417e-afdf-5ab6ff460511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataset object at 0x12e081590>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "自定义 Dataset\n",
    "torch.utils.data.Dataset 是一个抽象类，允许你从自己的数据源中创建数据集。\n",
    "\n",
    "我们需要继承该类并实现以下两个方法：\n",
    "\n",
    "__len__(self)：返回数据集中的样本数量。\n",
    "__getitem__(self, idx)：通过索引返回一个样本。\n",
    "假设我们有一个简单的 CSV 文件或一些列表数据，我们可以通过继承 Dataset 类来创建自己的数据集。\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 自定义数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        \"\"\"\n",
    "        初始化数据集，X_data 和 Y_data 是两个列表或数组\n",
    "        X_data: 输入特征\n",
    "        Y_data: 目标标签\n",
    "        \"\"\"\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集的大小\"\"\"\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"返回指定索引的数据\"\"\"\n",
    "        x = torch.tensor(self.X_data[idx], dtype=torch.float32)  # 转换为 Tensor\n",
    "        y = torch.tensor(self.Y_data[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# 示例数据\n",
    "X_data = [[1, 2], [3, 4], [5, 6], [7, 8]]  # 输入特征\n",
    "Y_data = [1, 0, 1, 0]  # 目标标签\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = MyDataset(X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3cc48b-68c3-4f8c-a70b-22855485986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Inputs: tensor([[7., 8.],\n",
      "        [1., 2.]])\n",
      "Labels: tensor([0., 1.])\n",
      "Batch 2:\n",
      "Inputs: tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "Labels: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "使用 DataLoader 加载数据\n",
    "DataLoader 是 PyTorch 提供的一个重要工具，用于从 Dataset 中按批次（batch）加载数据。\n",
    "\n",
    "DataLoader 允许我们批量读取数据并进行多线程加载，从而提高训练效率。\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "batch_size: 每次加载的样本数量。\n",
    "shuffle: 是否对数据进行洗牌，通常训练时需要将数据打乱。\n",
    "drop_last: 如果数据集中的样本数不能被 batch_size 整除，设置为 True 时，丢弃最后一个不完整的 batch。\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建 DataLoader 实例，batch_size 设置每次加载的样本数量\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 打印加载的数据\n",
    "for epoch in range(1):\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        print(f'Batch {batch_idx + 1}:')\n",
    "        print(f'Inputs: {inputs}')\n",
    "        print(f'Labels: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40caab99-8fae-4139-ac54-605c7e61cb9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/paroniasun/PyTorch/image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     15\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)),  \u001b[38;5;66;03m# 将图像调整为 128x128\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# 将图像转换为张量\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])  \u001b[38;5;66;03m# 标准化\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 加载图像\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 应用预处理\u001b[39;00m\n\u001b[1;32m     24\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m transform(image)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch_3.11/lib/python3.11/site-packages/PIL/Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/paroniasun/PyTorch/image.jpg'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "预处理与数据增强\n",
    "数据预处理和增强对于提高模型的性能至关重要。\n",
    "\n",
    "PyTorch 提供了 torchvision.transforms 模块来进行常见的图像预处理和增强操作，如旋转、裁剪、归一化等。\n",
    "\n",
    "常见的图像预处理操作:\n",
    "\"\"\"\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 定义数据预处理的流水线\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 将图像调整为 128x128\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "])\n",
    "\n",
    "# 加载图像\n",
    "image = Image.open('image.jpg')\n",
    "\n",
    "# 应用预处理\n",
    "image_tensor = transform(image)\n",
    "print(image_tensor.shape)  # 输出张量的形状\n",
    "\n",
    "\"\"\"\n",
    "transforms.Compose()：将多个变换操作组合在一起。\n",
    "transforms.Resize()：调整图像大小。\n",
    "transforms.ToTensor()：将图像转换为 PyTorch 张量，值会被归一化到 [0, 1] 范围。\n",
    "transforms.Normalize()：标准化图像数据，通常使用预训练模型时需要进行标准化处理。\n",
    "图像数据增强\n",
    "数据增强技术通过对训练数据进行随机变换，增加数据的多样性，帮助模型更好地泛化。例如，随机翻转、旋转、裁剪等。\n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomRotation(30),  # 随机旋转 30 度\n",
    "    transforms.RandomResizedCrop(128),  # 随机裁剪并调整为 128x128\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13f4a7-3e54-460f-b334-cdd2a0cb897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "加载图像数据集\n",
    "对于图像数据集，torchvision.datasets 提供了许多常见数据集（如 CIFAR-10、ImageNet、MNIST 等）以及用于加载图像数据的工具。\n",
    "\n",
    "加载 MNIST 数据集:\n",
    "\"\"\"\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义预处理操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 对灰度图像进行标准化\n",
    "])\n",
    "\n",
    "# 下载并加载 MNIST 数据集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 迭代训练数据\n",
    "for inputs, labels in train_loader:\n",
    "    print(inputs.shape)  # 每个批次的输入数据形状\n",
    "    print(labels.shape)  # 每个批次的标签形状\n",
    "\n",
    "\"\"\"\n",
    "datasets.MNIST() 会自动下载 MNIST 数据集并加载。\n",
    "transform 参数允许我们对数据进行预处理。\n",
    "train=True 和 train=False 分别表示训练集和测试集。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb314c-6472-4da9-8ff9-bd4292e4bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "用多个数据源（Multi-source Dataset）\n",
    "如果你的数据集由多个文件、多个来源（例如多个图像文件夹）组成，可以通过继承 Dataset 类自定义加载多个数据源。\n",
    "\n",
    "PyTorch 提供了 ConcatDataset 和 ChainDataset 等类来连接多个数据集。\n",
    "\n",
    "例如，假设我们有多个图像文件夹的数据，可以将它们合并为一个数据集：\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# 假设 dataset1 和 dataset2 是两个 Dataset 对象\n",
    "combined_dataset = ConcatDataset([dataset1, dataset2])\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
